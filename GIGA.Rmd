---
title: "GIGA III Conservation Genomics Workshop"
output:
  pdf_document:
    toc: yes
  html_document: default
linkcolor: blue
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir ="F:/PSU/Hybridization Project/SNPs/database")
```

Lead by Iliana Baums and Sheila Kitchen. Parts of this tutorial has been adapted from  [Galaxy tutorials](http://galaxyproject.github.io) and R package vingettes. 

### Outline of the topics covered:

    8:30-8:40am Advantages of Genomics in Conservation
    8:40-8:55am Group Discussion- Part I
    8:55-9:15am Read Mapping and Variant Calling -Galaxy
    9:15-9:25am Break
    9:25-9:45am Multilocus Genotyping- R software
    9:45-9:55am Group Discussion- Part II


###The Data
***
 In this example we will perform variant calling on a subset of three resequenced Caribbean _Acropora cervicornis_ coral genomes (Kitchen et al. 2018, _bioRxiv_) against the genome assembly of the Pacific acroporid, _Acropora digitifera_ (Shinzato et al. 2011, _Nature_). To speed things up, we downsampled the resequenced genomes for this exercise.
 
### Read Mapping
***
#### Data Import
In Galaxy, you can import the history with the files needed for the following steps as follows. 

1. Login with your credentials at usegalaxy.org
2. Import galaxy history with test datasets
    a. https://usegalaxy.org:/u/skitch/h/giga-iii-workshop-2018 
    b. Click on "Switch to this history" in the the upper right corner of the screen.


#### Read Mapping
Mapping of NGS reads against reference sequences is one of the key steps of the analysis. Below is a list of mainstream mapping tools available on Galaxy under **NGS:Mapping**:

- [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) 
- [BWA](https://github.com/lh3/bwa) - map reads < 100bp 
- [BWA-MEM](https://github.com/lh3/bwa)- map reads > 100 bp
- [LASTZ](https://github.com/lastz/lastz)

Mappers usually compare reads against a reference sequence that has been transformed into a highly accessible data structure called genome index. Such indexes should be generated before mapping begins. An index will be generated by default in Galaxy.

Run BWA-MEM tool on **Sample 4923** with the following parameters:

- _Choose the source for the reference genome_ = Use genome from history and build index
- _Use the following dataset as the reference sequence_: select the "scaf1_Adig.fasta"
- _Algorithm..._= Auto
- _Single or Paired-end reads_ = paired
- _insert mean_ = 350
- _Set read groups information?_ = Set read group (SAM/BAM specification)
- _Select analysis mode_ = 1. Simple Illumina mode
- _Job Resource Parameters_ = Default 

The SAM/BAM format is an accepted standard for storing aligned reads. The Sequence Alignment/Map (SAM) format is a generic nucleotide alignment format that describes the alignment of sequencing reads (or query sequences) to a reference. The binary form of the format (BAM) is compact and can be rapidly searched (if indexed). In Galaxy BAM datasets are always indexed (accompanies by a .bai file) and sorted in coordinate order.

We previously repeated the same process for the other two samples in the work history, **Sample 4960** and **Sample 14120**.

#### Remove PCR Duplicates
Preparation of sequencing libraries for technologies such as Illumina (used in this examples) typically involves PCR amplification. Duplicates can be identified based on their outer alignment coordinates or using sequence-based clustering. One of the common ways for identification of duplicate reads is the RmDup utility from SAMtools or MarkDuplicates utility from Picard package. It is designed to identify both PCR and optical duplicates.

Run MarkDuplicates tool on all three **BAM** files with the following parameters in **batch mode**:

- _Select SAM/BAM dataset or dataset collection_ = **Sample4923.bam** 
- _If true do not write duplicates..._ = change to "Yes"
- _Assume the input file is already sorted_ = "No"

This tool with have two outputs, a new BAM file with duplicates marked and a metric file about the original BAM. 

Descriptive statistics about each BAM file (# of paired reads, # of reads mapped, etc.) can be created using SAMtools **Flagstat** tool. 

### Variant Calling
***
#### How does SNP calling and genotyping work?
See the explanation [here](http://galaxyproject.github.io/training-material/topics/variant-analysis/tutorials/dip/tutorial.html).

Genotype estimation with likelihood approaches include GATK* and mpileup (SAMtools) while freebayes provides Bayesian posterior probabilities. mpileup to bcftools has been deprecated on Galaxy and their version of GATK is outdated. Therefore, today we will use freebayes.

Run FreeBayes tool with the following parameters:

- _Choose the source for the reference genome_ = history
- _Run in batch mode?_= Merge output vcfs
- _BAM dataset(s)_ = select all three BAM datasets
- _Using reference genome_ = scaf1_Adig.fasta
- _Choose parameter selection level_ = 2. Simple diploid calling...
- _Require at least this coverage to process a site_ = 3

This will produce genotype calls in the VCF format containing 1,496 putative variants.

*ALTERNATIVE OPTION- GATK position-based caller UnifiedGenotyper (not recommended by GATK, best practices now recommend HaplotypeCaller)

1. Merge the MarkDuplicte BAM files using the merge BAM files tool. 
2. Click the "UnifiedGenotyper" link under NGS:GATK Tools (beta)
    a. Select merged BAM file generated above
    b. Modify parameters or leave as default for now
3. Three files will be in the output, the VCF with genotype calls, metrics file and a run log.

GATK will also report a VCF file with genotype calls per site.

#### Filter VCF file
By default, freebayes outputs all SNP and indel variants. We would like to filter the variants such that they are "high-quality", bi-allelic SNPs, and present in all samples. 

    vcffilter -f "QUAL > 20 & TYPE = snp & NS > 2 " > results.vcf   

The QUAL field for freebayes can be interepreted as 1 - P(locus is homozygous given the data). The filter above removes any sites with estimated probability of not being polymorphic less than phred 20 (aka 0.01), or probability of polymorphism > 0.99, sites that are not labeled as SNP and sites with missing data for at least 1 sample.

We will run the VCFfilter tool in Galaxy with the filters above. This leaves 291 variants. If we impose a depth filter due to our our very small subset of reads used for the initial mapping. 

We will pick up with 2,419 SNPs that have been filtered from the full set of reads and samples as follows: mapping quality > 30, total depth < 1,200, bi-allelic snps only, and genotypes called for 100% of the individuals. These have also been filtered for fixed SNPs between species and geographic regions.

### Multilocus Genotyping
***
A multilocus genotype is the unique combination of the alleles for two or more loci for each individual. The multilocus genotypes are critically important for tracking dispersal and population structure of organisms, especially those that reproduce clonally (plants, sponges, cnidarians, flatworms, annelids, sea stars, and many more).


We will use the R package [Poppr](https://cran.r-project.org/web/packages/poppr/vignettes/mlg.html) (Kamvar et al. 2014, _PeerJ_; Kamvar et al. 2015, _Frontiers_)  to generate MLGs for our samples.


Install and load the packages required for the analyses.
```{r warning=FALSE, message=FALSE}
#Required R-packages for multi-locus genotype calling
#install.packages("vcfR")
library(vcfR)
#install.packages("poppr")
library(poppr)
#install.packages("adegenet")
library(adegenet)
#install.packages("ape")
library(ape)
#install.packages("ggplot2")
library(ggplot2)
library(knitr)
```


Import the VCF file:
```{r}
#Read in VCF file with array SNVs
vcf <- read.vcfR(file.choose())

```


Convert VCF file into formats compatiable with the Poppr package:
```{r}
#genind object
gind <- vcfR2genind(vcf)
#add population information to the genind object
poptab<-read.table(file.choose(),check.names=FALSE, header=T, na.strings = c("", "NA"))
gind@pop <- as.factor(poptab$region)
gind

#convert genind to genclone object
gclo<-as.genclone(gind)
gclo
```


We need to calcualte the genetic distance between the individuals.The bitwise.dist() function will calculate the fraction of alleles different between samples. This function is equivalent to the  Provesti's distance that counts missing data as equivalent in comparison. 
```{r}
#calculate the bitwise distance between individuals
xdis<-bitwise.dist(gclo) #similar to Provesti's distance
head(xdis)
#to show that they are the same
xdis2<-provesti.dist(gclo)
head(xdis2)
```


Next, we will estimate the MLGs based on the genetics distance matrix. 

Our first attempt will require all alleles must match to make a unique multilocus genotype ("original" naive approach). This is the default behavior of _poppr_.
```{r}
mll(gclo)<-"original"
gclo
```


The method above does not take the genetic distance into account, but we can use this matrix to collapse MLGs that are under a specified distance threshold. In this case, we know that samples 14120 and 4960 are clonemates (ramets from the same genet) based on microsatellite data. To determine the distance threshold, we will generate a neighbor-joining tree for all samples. 

```{r}
##Create a phylogeny of samples based on distance matrices
#colors
cols <- c("skyblue2","#C38D9E", '#E8A87C',"darkcyan","#e27d60")

set.seed(999)

theTree <-  gclo %>%
  aboot(dist = provesti.dist, sample = 50, tree = "nj",
        cutoff = 50, quiet = TRUE) %>%
  ladderize() # organize branches by clade
plot.phylo(theTree, tip.color = cols[gclo$pop],label.offset = 0.0125,cex=0.7, 
           font=2, lwd=4)
add.scale.bar(length = 0.05, cex=0.65) # add a scale bar showing 5% difference.
nodelabels(theTree$node.label, cex=.5, adj = c(1.5, -0.1), frame = "n", font=3,
           xpd = TRUE)

#extract Provesti's distance from the distance matrix
d <- function(distance, selection){
  eval(parse(text = paste("as.matrix(distance)[",
               selection, "]")))
}
d(xdis2, "27, 21") #sample 4960 v. 14120

d(xdis2,"34,35") #sample 13797 v. 13792

d(xdis2,"3,4") #sample 1302 v. 1303

d(xdis2,"5,16") #sample 13764 v. 1835
```


We will set our threshold to 0.01 based on the distance between 4960 and 14120. Use of mlg.filter() will create a dissimiliarity distance matrix from the data and then filter based off of that matrix. Here we will use the bitwise distance matrix calculated above. 
```{r}
#multilocus genotypes (threshold of 1%)
mlg.filter(gclo, distance= xdis)<- 0.01
m<-mlg.table(gclo, background=TRUE, color=TRUE)
nmll(gclo,"contracted")

#different clustering methods for tie breakers used by mlg.filter, default is farthest neighbor
gclo_filtered <- filter_stats(gclo, distance = xdis, plot = TRUE)
print(farthest_thresh <- cutoff_predictor(gclo_filtered$farthest$THRESHOLDS))
print(average_thresh  <- cutoff_predictor(gclo_filtered$average$THRESHOLDS))
print(nearest_thresh  <- cutoff_predictor(gclo_filtered$nearest$THRESHOLDS))
#define filter based on farthest neighbor threshold
#mlg.filter(gclo, distance= xdis)<-farthest_thresh

#create table of MLGs
id<-mlg.id(gclo)
df <- data.frame(matrix((id), byrow=T))
df
#write.table(df,file="mlg-id.txt")
```


We can use the genotype_curve() function to create a genotype accumulation curve to determine the minimum number of loci to identify unique MLGs. 
```{r}
#genotype accumulation curve, sample = number of loci randomly selected to make the curve
gac <- genotype_curve(gind, sample = 5, quiet = TRUE)
p <- last_plot()
p + geom_smooth() +xlim(0,100)+theme_bw()
```


From the collapsed MLGs, we can calculate genotypic richness, diversity and eveness
```{r}
kable(poppr(gclo))
#H = Shannon-Wiener Index of MLG diversity (Shannon, 2001).
#G = Stoddart and Taylor's Index of MLG diversity  (Stoddart & Taylor, 1988).
#lambda = Simpson's Index (Simpson, 1949).
#E.5 = Evenness, E5(Pielou, 1975; Ludwig & Reynolds, 1988; GrÃ¼nwald et al., 2003).
#Hexp = Nei's unbiased gene diversity (Nei, 1978).
#Ia = The index of association, IA (Brown, Feldman & Nevo, 1980; Smith et al., 1993).
#rbarD = The standardized index of association

kable(diversity_ci(gclo, n=100L, raw=FALSE ))
```


Now we can correct the original data for clones using clonecorrect. This step will reduce the dataset to only have 1 representative genotype per multilocus lineages (MLL).
```{r}
gclo_cor <- clonecorrect(gclo, strata = NA)
```


Lastly, we can use a discriminant analysis of principal components to cluster genetically related individuals. This multivariate statistical approach partions the sample into a between-group and within- group component, in an effort to maximize discrimination between groups. Data is first transformed using a principal components analysis (PCA) and subsequently clusters are identified using discriminant analysis (DA).More information can be found [here](http://adegenet.r-forge.r-project.org/files/tutorial-dapc.pdf). 

```{r}
dapc.coral <- dapc(gclo_cor, var.contrib = TRUE, scale = FALSE, 
                   n.pca = 62, n.da = nPop(gclo_cor) - 1)
scatter(dapc.coral, cell = 0, pch = 18:23, cstar = 0, lwd = 2, 
        lty = 2, legend = TRUE,cleg = 0.75,clabel = TRUE, col=cols)
```

